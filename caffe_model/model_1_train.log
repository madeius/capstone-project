I1209 11:05:39.035142  1721 caffe.cpp:185] Using GPUs 0
I1209 11:05:39.425089  1721 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 5000
snapshot_prefix: "/home/ubuntu/cats-dogs/caffe_model/caffe_model_1"
solver_mode: GPU
device_id: 0
net: "/home/ubuntu/cats-dogs/caffe_model/caffenet_train_val_1.prototxt"
I1209 11:05:39.425276  1721 solver.cpp:91] Creating training net from net file: /home/ubuntu/cats-dogs/caffe_model/caffenet_train_val_1.prototxt
I1209 11:05:39.426157  1721 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1209 11:05:39.426198  1721 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1209 11:05:39.426434  1721 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/ubuntu/cats-dogs/input/mean.binaryproto"
  }
  data_param {
    source: "/home/ubuntu/cats-dogs/input/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1209 11:05:39.426635  1721 layer_factory.hpp:77] Creating layer data
I1209 11:05:39.427732  1721 net.cpp:106] Creating Layer data
I1209 11:05:39.427754  1721 net.cpp:411] data -> data
I1209 11:05:39.427796  1721 net.cpp:411] data -> label
I1209 11:05:39.427822  1721 data_transformer.cpp:25] Loading mean file from: /home/ubuntu/cats-dogs/input/mean.binaryproto
I1209 11:05:39.428455  1728 db_lmdb.cpp:38] Opened lmdb /home/ubuntu/cats-dogs/input/train_lmdb
I1209 11:05:39.441543  1721 data_layer.cpp:41] output data size: 256,3,227,227
I1209 11:05:39.745002  1721 net.cpp:150] Setting up data
I1209 11:05:39.745067  1721 net.cpp:157] Top shape: 256 3 227 227 (39574272)
I1209 11:05:39.745076  1721 net.cpp:157] Top shape: 256 (256)
I1209 11:05:39.745082  1721 net.cpp:165] Memory required for data: 158298112
I1209 11:05:39.745101  1721 layer_factory.hpp:77] Creating layer conv1
I1209 11:05:39.745141  1721 net.cpp:106] Creating Layer conv1
I1209 11:05:39.745159  1721 net.cpp:454] conv1 <- data
I1209 11:05:39.745184  1721 net.cpp:411] conv1 -> conv1
I1209 11:05:39.886380  1721 net.cpp:150] Setting up conv1
I1209 11:05:39.886430  1721 net.cpp:157] Top shape: 256 96 55 55 (74342400)
I1209 11:05:39.886435  1721 net.cpp:165] Memory required for data: 455667712
I1209 11:05:39.886473  1721 layer_factory.hpp:77] Creating layer relu1
I1209 11:05:39.886497  1721 net.cpp:106] Creating Layer relu1
I1209 11:05:39.886512  1721 net.cpp:454] relu1 <- conv1
I1209 11:05:39.886523  1721 net.cpp:397] relu1 -> conv1 (in-place)
I1209 11:05:39.886690  1721 net.cpp:150] Setting up relu1
I1209 11:05:39.886709  1721 net.cpp:157] Top shape: 256 96 55 55 (74342400)
I1209 11:05:39.886715  1721 net.cpp:165] Memory required for data: 753037312
I1209 11:05:39.886721  1721 layer_factory.hpp:77] Creating layer pool1
I1209 11:05:39.886735  1721 net.cpp:106] Creating Layer pool1
I1209 11:05:39.886741  1721 net.cpp:454] pool1 <- conv1
I1209 11:05:39.886749  1721 net.cpp:411] pool1 -> pool1
I1209 11:05:39.886816  1721 net.cpp:150] Setting up pool1
I1209 11:05:39.886833  1721 net.cpp:157] Top shape: 256 96 27 27 (17915904)
I1209 11:05:39.886838  1721 net.cpp:165] Memory required for data: 824700928
I1209 11:05:39.886871  1721 layer_factory.hpp:77] Creating layer norm1
I1209 11:05:39.886898  1721 net.cpp:106] Creating Layer norm1
I1209 11:05:39.886914  1721 net.cpp:454] norm1 <- pool1
I1209 11:05:39.886922  1721 net.cpp:411] norm1 -> norm1
I1209 11:05:39.887207  1721 net.cpp:150] Setting up norm1
I1209 11:05:39.887229  1721 net.cpp:157] Top shape: 256 96 27 27 (17915904)
I1209 11:05:39.887235  1721 net.cpp:165] Memory required for data: 896364544
I1209 11:05:39.887241  1721 layer_factory.hpp:77] Creating layer conv2
I1209 11:05:39.887259  1721 net.cpp:106] Creating Layer conv2
I1209 11:05:39.887265  1721 net.cpp:454] conv2 <- norm1
I1209 11:05:39.887274  1721 net.cpp:411] conv2 -> conv2
I1209 11:05:39.899616  1721 net.cpp:150] Setting up conv2
I1209 11:05:39.899667  1721 net.cpp:157] Top shape: 256 256 27 27 (47775744)
I1209 11:05:39.899672  1721 net.cpp:165] Memory required for data: 1087467520
I1209 11:05:39.899695  1721 layer_factory.hpp:77] Creating layer relu2
I1209 11:05:39.899713  1721 net.cpp:106] Creating Layer relu2
I1209 11:05:39.899719  1721 net.cpp:454] relu2 <- conv2
I1209 11:05:39.899729  1721 net.cpp:397] relu2 -> conv2 (in-place)
I1209 11:05:39.899991  1721 net.cpp:150] Setting up relu2
I1209 11:05:39.900012  1721 net.cpp:157] Top shape: 256 256 27 27 (47775744)
I1209 11:05:39.900017  1721 net.cpp:165] Memory required for data: 1278570496
I1209 11:05:39.900023  1721 layer_factory.hpp:77] Creating layer pool2
I1209 11:05:39.900038  1721 net.cpp:106] Creating Layer pool2
I1209 11:05:39.900043  1721 net.cpp:454] pool2 <- conv2
I1209 11:05:39.900050  1721 net.cpp:411] pool2 -> pool2
I1209 11:05:39.900108  1721 net.cpp:150] Setting up pool2
I1209 11:05:39.900127  1721 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I1209 11:05:39.900132  1721 net.cpp:165] Memory required for data: 1322872832
I1209 11:05:39.900138  1721 layer_factory.hpp:77] Creating layer norm2
I1209 11:05:39.900154  1721 net.cpp:106] Creating Layer norm2
I1209 11:05:39.900162  1721 net.cpp:454] norm2 <- pool2
I1209 11:05:39.900169  1721 net.cpp:411] norm2 -> norm2
I1209 11:05:39.900342  1721 net.cpp:150] Setting up norm2
I1209 11:05:39.900362  1721 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I1209 11:05:39.900367  1721 net.cpp:165] Memory required for data: 1367175168
I1209 11:05:39.900372  1721 layer_factory.hpp:77] Creating layer conv3
I1209 11:05:39.900390  1721 net.cpp:106] Creating Layer conv3
I1209 11:05:39.900396  1721 net.cpp:454] conv3 <- norm2
I1209 11:05:39.900408  1721 net.cpp:411] conv3 -> conv3
I1209 11:05:39.931140  1721 net.cpp:150] Setting up conv3
I1209 11:05:39.931195  1721 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I1209 11:05:39.931202  1721 net.cpp:165] Memory required for data: 1433628672
I1209 11:05:39.931231  1721 layer_factory.hpp:77] Creating layer relu3
I1209 11:05:39.931251  1721 net.cpp:106] Creating Layer relu3
I1209 11:05:39.931258  1721 net.cpp:454] relu3 <- conv3
I1209 11:05:39.931270  1721 net.cpp:397] relu3 -> conv3 (in-place)
I1209 11:05:39.931546  1721 net.cpp:150] Setting up relu3
I1209 11:05:39.931569  1721 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I1209 11:05:39.931574  1721 net.cpp:165] Memory required for data: 1500082176
I1209 11:05:39.931581  1721 layer_factory.hpp:77] Creating layer conv4
I1209 11:05:39.931602  1721 net.cpp:106] Creating Layer conv4
I1209 11:05:39.931617  1721 net.cpp:454] conv4 <- conv3
I1209 11:05:39.931629  1721 net.cpp:411] conv4 -> conv4
I1209 11:05:39.955466  1721 net.cpp:150] Setting up conv4
I1209 11:05:39.955500  1721 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I1209 11:05:39.955507  1721 net.cpp:165] Memory required for data: 1566535680
I1209 11:05:39.955520  1721 layer_factory.hpp:77] Creating layer relu4
I1209 11:05:39.955538  1721 net.cpp:106] Creating Layer relu4
I1209 11:05:39.955544  1721 net.cpp:454] relu4 <- conv4
I1209 11:05:39.955554  1721 net.cpp:397] relu4 -> conv4 (in-place)
I1209 11:05:39.955811  1721 net.cpp:150] Setting up relu4
I1209 11:05:39.955832  1721 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I1209 11:05:39.955837  1721 net.cpp:165] Memory required for data: 1632989184
I1209 11:05:39.955865  1721 layer_factory.hpp:77] Creating layer conv5
I1209 11:05:39.955884  1721 net.cpp:106] Creating Layer conv5
I1209 11:05:39.955898  1721 net.cpp:454] conv5 <- conv4
I1209 11:05:39.955909  1721 net.cpp:411] conv5 -> conv5
I1209 11:05:39.972744  1721 net.cpp:150] Setting up conv5
I1209 11:05:39.972798  1721 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I1209 11:05:39.972805  1721 net.cpp:165] Memory required for data: 1677291520
I1209 11:05:39.972827  1721 layer_factory.hpp:77] Creating layer relu5
I1209 11:05:39.972846  1721 net.cpp:106] Creating Layer relu5
I1209 11:05:39.972852  1721 net.cpp:454] relu5 <- conv5
I1209 11:05:39.972863  1721 net.cpp:397] relu5 -> conv5 (in-place)
I1209 11:05:39.973022  1721 net.cpp:150] Setting up relu5
I1209 11:05:39.973047  1721 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I1209 11:05:39.973053  1721 net.cpp:165] Memory required for data: 1721593856
I1209 11:05:39.973059  1721 layer_factory.hpp:77] Creating layer pool5
I1209 11:05:39.973070  1721 net.cpp:106] Creating Layer pool5
I1209 11:05:39.973074  1721 net.cpp:454] pool5 <- conv5
I1209 11:05:39.973083  1721 net.cpp:411] pool5 -> pool5
I1209 11:05:39.973139  1721 net.cpp:150] Setting up pool5
I1209 11:05:39.973155  1721 net.cpp:157] Top shape: 256 256 6 6 (2359296)
I1209 11:05:39.973160  1721 net.cpp:165] Memory required for data: 1731031040
I1209 11:05:39.973165  1721 layer_factory.hpp:77] Creating layer fc6
I1209 11:05:39.973187  1721 net.cpp:106] Creating Layer fc6
I1209 11:05:39.973199  1721 net.cpp:454] fc6 <- pool5
I1209 11:05:39.973211  1721 net.cpp:411] fc6 -> fc6
I1209 11:05:41.239739  1721 net.cpp:150] Setting up fc6
I1209 11:05:41.239794  1721 net.cpp:157] Top shape: 256 4096 (1048576)
I1209 11:05:41.239800  1721 net.cpp:165] Memory required for data: 1735225344
I1209 11:05:41.239817  1721 layer_factory.hpp:77] Creating layer relu6
I1209 11:05:41.239836  1721 net.cpp:106] Creating Layer relu6
I1209 11:05:41.239845  1721 net.cpp:454] relu6 <- fc6
I1209 11:05:41.239858  1721 net.cpp:397] relu6 -> fc6 (in-place)
I1209 11:05:41.240331  1721 net.cpp:150] Setting up relu6
I1209 11:05:41.240353  1721 net.cpp:157] Top shape: 256 4096 (1048576)
I1209 11:05:41.240360  1721 net.cpp:165] Memory required for data: 1739419648
I1209 11:05:41.240365  1721 layer_factory.hpp:77] Creating layer drop6
I1209 11:05:41.240386  1721 net.cpp:106] Creating Layer drop6
I1209 11:05:41.240393  1721 net.cpp:454] drop6 <- fc6
I1209 11:05:41.240402  1721 net.cpp:397] drop6 -> fc6 (in-place)
I1209 11:05:41.240442  1721 net.cpp:150] Setting up drop6
I1209 11:05:41.240458  1721 net.cpp:157] Top shape: 256 4096 (1048576)
I1209 11:05:41.240463  1721 net.cpp:165] Memory required for data: 1743613952
I1209 11:05:41.240468  1721 layer_factory.hpp:77] Creating layer fc7
I1209 11:05:41.240487  1721 net.cpp:106] Creating Layer fc7
I1209 11:05:41.240494  1721 net.cpp:454] fc7 <- fc6
I1209 11:05:41.240505  1721 net.cpp:411] fc7 -> fc7
I1209 11:05:41.802417  1721 net.cpp:150] Setting up fc7
I1209 11:05:41.802472  1721 net.cpp:157] Top shape: 256 4096 (1048576)
I1209 11:05:41.802479  1721 net.cpp:165] Memory required for data: 1747808256
I1209 11:05:41.802495  1721 layer_factory.hpp:77] Creating layer relu7
I1209 11:05:41.802517  1721 net.cpp:106] Creating Layer relu7
I1209 11:05:41.802526  1721 net.cpp:454] relu7 <- fc7
I1209 11:05:41.802537  1721 net.cpp:397] relu7 -> fc7 (in-place)
I1209 11:05:41.802799  1721 net.cpp:150] Setting up relu7
I1209 11:05:41.802819  1721 net.cpp:157] Top shape: 256 4096 (1048576)
I1209 11:05:41.802824  1721 net.cpp:165] Memory required for data: 1752002560
I1209 11:05:41.802830  1721 layer_factory.hpp:77] Creating layer drop7
I1209 11:05:41.802840  1721 net.cpp:106] Creating Layer drop7
I1209 11:05:41.802845  1721 net.cpp:454] drop7 <- fc7
I1209 11:05:41.802855  1721 net.cpp:397] drop7 -> fc7 (in-place)
I1209 11:05:41.802886  1721 net.cpp:150] Setting up drop7
I1209 11:05:41.802906  1721 net.cpp:157] Top shape: 256 4096 (1048576)
I1209 11:05:41.802917  1721 net.cpp:165] Memory required for data: 1756196864
I1209 11:05:41.802945  1721 layer_factory.hpp:77] Creating layer fc8
I1209 11:05:41.802965  1721 net.cpp:106] Creating Layer fc8
I1209 11:05:41.802973  1721 net.cpp:454] fc8 <- fc7
I1209 11:05:41.802981  1721 net.cpp:411] fc8 -> fc8
I1209 11:05:41.804008  1721 net.cpp:150] Setting up fc8
I1209 11:05:41.804028  1721 net.cpp:157] Top shape: 256 2 (512)
I1209 11:05:41.804033  1721 net.cpp:165] Memory required for data: 1756198912
I1209 11:05:41.804042  1721 layer_factory.hpp:77] Creating layer loss
I1209 11:05:41.804059  1721 net.cpp:106] Creating Layer loss
I1209 11:05:41.804067  1721 net.cpp:454] loss <- fc8
I1209 11:05:41.804074  1721 net.cpp:454] loss <- label
I1209 11:05:41.804085  1721 net.cpp:411] loss -> loss
I1209 11:05:41.804106  1721 layer_factory.hpp:77] Creating layer loss
I1209 11:05:41.804498  1721 net.cpp:150] Setting up loss
I1209 11:05:41.804519  1721 net.cpp:157] Top shape: (1)
I1209 11:05:41.804525  1721 net.cpp:160]     with loss weight 1
I1209 11:05:41.804571  1721 net.cpp:165] Memory required for data: 1756198916
I1209 11:05:41.804579  1721 net.cpp:226] loss needs backward computation.
I1209 11:05:41.804584  1721 net.cpp:226] fc8 needs backward computation.
I1209 11:05:41.804589  1721 net.cpp:226] drop7 needs backward computation.
I1209 11:05:41.804594  1721 net.cpp:226] relu7 needs backward computation.
I1209 11:05:41.804597  1721 net.cpp:226] fc7 needs backward computation.
I1209 11:05:41.804601  1721 net.cpp:226] drop6 needs backward computation.
I1209 11:05:41.804606  1721 net.cpp:226] relu6 needs backward computation.
I1209 11:05:41.804610  1721 net.cpp:226] fc6 needs backward computation.
I1209 11:05:41.804615  1721 net.cpp:226] pool5 needs backward computation.
I1209 11:05:41.804620  1721 net.cpp:226] relu5 needs backward computation.
I1209 11:05:41.804625  1721 net.cpp:226] conv5 needs backward computation.
I1209 11:05:41.804630  1721 net.cpp:226] relu4 needs backward computation.
I1209 11:05:41.804633  1721 net.cpp:226] conv4 needs backward computation.
I1209 11:05:41.804638  1721 net.cpp:226] relu3 needs backward computation.
I1209 11:05:41.804642  1721 net.cpp:226] conv3 needs backward computation.
I1209 11:05:41.804647  1721 net.cpp:226] norm2 needs backward computation.
I1209 11:05:41.804652  1721 net.cpp:226] pool2 needs backward computation.
I1209 11:05:41.804656  1721 net.cpp:226] relu2 needs backward computation.
I1209 11:05:41.804661  1721 net.cpp:226] conv2 needs backward computation.
I1209 11:05:41.804666  1721 net.cpp:226] norm1 needs backward computation.
I1209 11:05:41.804671  1721 net.cpp:226] pool1 needs backward computation.
I1209 11:05:41.804675  1721 net.cpp:226] relu1 needs backward computation.
I1209 11:05:41.804679  1721 net.cpp:226] conv1 needs backward computation.
I1209 11:05:41.804684  1721 net.cpp:228] data does not need backward computation.
I1209 11:05:41.804692  1721 net.cpp:270] This network produces output loss
I1209 11:05:41.804720  1721 net.cpp:283] Network initialization done.
I1209 11:05:41.805577  1721 solver.cpp:181] Creating test net (#0) specified by net file: /home/ubuntu/cats-dogs/caffe_model/caffenet_train_val_1.prototxt
I1209 11:05:41.805646  1721 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1209 11:05:41.805889  1721 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ubuntu/cats-dogs/input/mean.binaryproto"
  }
  data_param {
    source: "/home/ubuntu/cats-dogs/input/validation_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1209 11:05:41.806080  1721 layer_factory.hpp:77] Creating layer data
I1209 11:05:41.806201  1721 net.cpp:106] Creating Layer data
I1209 11:05:41.806212  1721 net.cpp:411] data -> data
I1209 11:05:41.806224  1721 net.cpp:411] data -> label
I1209 11:05:41.806237  1721 data_transformer.cpp:25] Loading mean file from: /home/ubuntu/cats-dogs/input/mean.binaryproto
I1209 11:05:41.806993  1730 db_lmdb.cpp:38] Opened lmdb /home/ubuntu/cats-dogs/input/validation_lmdb
I1209 11:05:41.808754  1721 data_layer.cpp:41] output data size: 50,3,227,227
I1209 11:05:41.869027  1721 net.cpp:150] Setting up data
I1209 11:05:41.869083  1721 net.cpp:157] Top shape: 50 3 227 227 (7729350)
I1209 11:05:41.869092  1721 net.cpp:157] Top shape: 50 (50)
I1209 11:05:41.869097  1721 net.cpp:165] Memory required for data: 30917600
I1209 11:05:41.869108  1721 layer_factory.hpp:77] Creating layer label_data_1_split
I1209 11:05:41.869129  1721 net.cpp:106] Creating Layer label_data_1_split
I1209 11:05:41.869137  1721 net.cpp:454] label_data_1_split <- label
I1209 11:05:41.869148  1721 net.cpp:411] label_data_1_split -> label_data_1_split_0
I1209 11:05:41.869164  1721 net.cpp:411] label_data_1_split -> label_data_1_split_1
I1209 11:05:41.869324  1721 net.cpp:150] Setting up label_data_1_split
I1209 11:05:41.869343  1721 net.cpp:157] Top shape: 50 (50)
I1209 11:05:41.869350  1721 net.cpp:157] Top shape: 50 (50)
I1209 11:05:41.869354  1721 net.cpp:165] Memory required for data: 30918000
I1209 11:05:41.869359  1721 layer_factory.hpp:77] Creating layer conv1
I1209 11:05:41.869382  1721 net.cpp:106] Creating Layer conv1
I1209 11:05:41.869393  1721 net.cpp:454] conv1 <- data
I1209 11:05:41.869403  1721 net.cpp:411] conv1 -> conv1
I1209 11:05:41.874285  1721 net.cpp:150] Setting up conv1
I1209 11:05:41.874310  1721 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I1209 11:05:41.874316  1721 net.cpp:165] Memory required for data: 88998000
I1209 11:05:41.874333  1721 layer_factory.hpp:77] Creating layer relu1
I1209 11:05:41.874347  1721 net.cpp:106] Creating Layer relu1
I1209 11:05:41.874353  1721 net.cpp:454] relu1 <- conv1
I1209 11:05:41.874361  1721 net.cpp:397] relu1 -> conv1 (in-place)
I1209 11:05:41.874522  1721 net.cpp:150] Setting up relu1
I1209 11:05:41.874541  1721 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I1209 11:05:41.874547  1721 net.cpp:165] Memory required for data: 147078000
I1209 11:05:41.874552  1721 layer_factory.hpp:77] Creating layer pool1
I1209 11:05:41.874565  1721 net.cpp:106] Creating Layer pool1
I1209 11:05:41.874570  1721 net.cpp:454] pool1 <- conv1
I1209 11:05:41.874578  1721 net.cpp:411] pool1 -> pool1
I1209 11:05:41.874630  1721 net.cpp:150] Setting up pool1
I1209 11:05:41.874646  1721 net.cpp:157] Top shape: 50 96 27 27 (3499200)
I1209 11:05:41.874651  1721 net.cpp:165] Memory required for data: 161074800
I1209 11:05:41.874656  1721 layer_factory.hpp:77] Creating layer norm1
I1209 11:05:41.874670  1721 net.cpp:106] Creating Layer norm1
I1209 11:05:41.874675  1721 net.cpp:454] norm1 <- pool1
I1209 11:05:41.874681  1721 net.cpp:411] norm1 -> norm1
I1209 11:05:41.874965  1721 net.cpp:150] Setting up norm1
I1209 11:05:41.874986  1721 net.cpp:157] Top shape: 50 96 27 27 (3499200)
I1209 11:05:41.874992  1721 net.cpp:165] Memory required for data: 175071600
I1209 11:05:41.874997  1721 layer_factory.hpp:77] Creating layer conv2
I1209 11:05:41.875012  1721 net.cpp:106] Creating Layer conv2
I1209 11:05:41.875018  1721 net.cpp:454] conv2 <- norm1
I1209 11:05:41.875027  1721 net.cpp:411] conv2 -> conv2
I1209 11:05:41.886986  1721 net.cpp:150] Setting up conv2
I1209 11:05:41.887029  1721 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I1209 11:05:41.887035  1721 net.cpp:165] Memory required for data: 212396400
I1209 11:05:41.887089  1721 layer_factory.hpp:77] Creating layer relu2
I1209 11:05:41.887112  1721 net.cpp:106] Creating Layer relu2
I1209 11:05:41.887123  1721 net.cpp:454] relu2 <- conv2
I1209 11:05:41.887137  1721 net.cpp:397] relu2 -> conv2 (in-place)
I1209 11:05:41.887399  1721 net.cpp:150] Setting up relu2
I1209 11:05:41.887420  1721 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I1209 11:05:41.887425  1721 net.cpp:165] Memory required for data: 249721200
I1209 11:05:41.887431  1721 layer_factory.hpp:77] Creating layer pool2
I1209 11:05:41.887446  1721 net.cpp:106] Creating Layer pool2
I1209 11:05:41.887451  1721 net.cpp:454] pool2 <- conv2
I1209 11:05:41.887460  1721 net.cpp:411] pool2 -> pool2
I1209 11:05:41.887526  1721 net.cpp:150] Setting up pool2
I1209 11:05:41.887543  1721 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I1209 11:05:41.887549  1721 net.cpp:165] Memory required for data: 258374000
I1209 11:05:41.887554  1721 layer_factory.hpp:77] Creating layer norm2
I1209 11:05:41.887567  1721 net.cpp:106] Creating Layer norm2
I1209 11:05:41.887572  1721 net.cpp:454] norm2 <- pool2
I1209 11:05:41.887579  1721 net.cpp:411] norm2 -> norm2
I1209 11:05:41.887763  1721 net.cpp:150] Setting up norm2
I1209 11:05:41.887783  1721 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I1209 11:05:41.887789  1721 net.cpp:165] Memory required for data: 267026800
I1209 11:05:41.887794  1721 layer_factory.hpp:77] Creating layer conv3
I1209 11:05:41.887810  1721 net.cpp:106] Creating Layer conv3
I1209 11:05:41.887817  1721 net.cpp:454] conv3 <- norm2
I1209 11:05:41.887826  1721 net.cpp:411] conv3 -> conv3
I1209 11:05:41.918618  1721 net.cpp:150] Setting up conv3
I1209 11:05:41.918671  1721 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I1209 11:05:41.918678  1721 net.cpp:165] Memory required for data: 280006000
I1209 11:05:41.918701  1721 layer_factory.hpp:77] Creating layer relu3
I1209 11:05:41.918720  1721 net.cpp:106] Creating Layer relu3
I1209 11:05:41.918735  1721 net.cpp:454] relu3 <- conv3
I1209 11:05:41.918747  1721 net.cpp:397] relu3 -> conv3 (in-place)
I1209 11:05:41.919000  1721 net.cpp:150] Setting up relu3
I1209 11:05:41.919021  1721 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I1209 11:05:41.919028  1721 net.cpp:165] Memory required for data: 292985200
I1209 11:05:41.919033  1721 layer_factory.hpp:77] Creating layer conv4
I1209 11:05:41.919051  1721 net.cpp:106] Creating Layer conv4
I1209 11:05:41.919059  1721 net.cpp:454] conv4 <- conv3
I1209 11:05:41.919069  1721 net.cpp:411] conv4 -> conv4
I1209 11:05:41.946930  1721 net.cpp:150] Setting up conv4
I1209 11:05:41.946979  1721 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I1209 11:05:41.946985  1721 net.cpp:165] Memory required for data: 305964400
I1209 11:05:41.947000  1721 layer_factory.hpp:77] Creating layer relu4
I1209 11:05:41.947018  1721 net.cpp:106] Creating Layer relu4
I1209 11:05:41.947026  1721 net.cpp:454] relu4 <- conv4
I1209 11:05:41.947038  1721 net.cpp:397] relu4 -> conv4 (in-place)
I1209 11:05:41.947315  1721 net.cpp:150] Setting up relu4
I1209 11:05:41.947336  1721 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I1209 11:05:41.947342  1721 net.cpp:165] Memory required for data: 318943600
I1209 11:05:41.947347  1721 layer_factory.hpp:77] Creating layer conv5
I1209 11:05:41.947366  1721 net.cpp:106] Creating Layer conv5
I1209 11:05:41.947378  1721 net.cpp:454] conv5 <- conv4
I1209 11:05:41.947389  1721 net.cpp:411] conv5 -> conv5
I1209 11:05:41.963927  1721 net.cpp:150] Setting up conv5
I1209 11:05:41.963975  1721 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I1209 11:05:41.963981  1721 net.cpp:165] Memory required for data: 327596400
I1209 11:05:41.964004  1721 layer_factory.hpp:77] Creating layer relu5
I1209 11:05:41.964022  1721 net.cpp:106] Creating Layer relu5
I1209 11:05:41.964037  1721 net.cpp:454] relu5 <- conv5
I1209 11:05:41.964049  1721 net.cpp:397] relu5 -> conv5 (in-place)
I1209 11:05:41.964313  1721 net.cpp:150] Setting up relu5
I1209 11:05:41.964334  1721 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I1209 11:05:41.964365  1721 net.cpp:165] Memory required for data: 336249200
I1209 11:05:41.964370  1721 layer_factory.hpp:77] Creating layer pool5
I1209 11:05:41.964387  1721 net.cpp:106] Creating Layer pool5
I1209 11:05:41.964399  1721 net.cpp:454] pool5 <- conv5
I1209 11:05:41.964409  1721 net.cpp:411] pool5 -> pool5
I1209 11:05:41.964473  1721 net.cpp:150] Setting up pool5
I1209 11:05:41.964488  1721 net.cpp:157] Top shape: 50 256 6 6 (460800)
I1209 11:05:41.964493  1721 net.cpp:165] Memory required for data: 338092400
I1209 11:05:41.964498  1721 layer_factory.hpp:77] Creating layer fc6
I1209 11:05:41.964511  1721 net.cpp:106] Creating Layer fc6
I1209 11:05:41.964516  1721 net.cpp:454] fc6 <- pool5
I1209 11:05:41.964525  1721 net.cpp:411] fc6 -> fc6
I1209 11:05:43.231022  1721 net.cpp:150] Setting up fc6
I1209 11:05:43.231082  1721 net.cpp:157] Top shape: 50 4096 (204800)
I1209 11:05:43.231089  1721 net.cpp:165] Memory required for data: 338911600
I1209 11:05:43.231106  1721 layer_factory.hpp:77] Creating layer relu6
I1209 11:05:43.231124  1721 net.cpp:106] Creating Layer relu6
I1209 11:05:43.231132  1721 net.cpp:454] relu6 <- fc6
I1209 11:05:43.231144  1721 net.cpp:397] relu6 -> fc6 (in-place)
I1209 11:05:43.231418  1721 net.cpp:150] Setting up relu6
I1209 11:05:43.231438  1721 net.cpp:157] Top shape: 50 4096 (204800)
I1209 11:05:43.231443  1721 net.cpp:165] Memory required for data: 339730800
I1209 11:05:43.231449  1721 layer_factory.hpp:77] Creating layer drop6
I1209 11:05:43.231461  1721 net.cpp:106] Creating Layer drop6
I1209 11:05:43.231465  1721 net.cpp:454] drop6 <- fc6
I1209 11:05:43.231474  1721 net.cpp:397] drop6 -> fc6 (in-place)
I1209 11:05:43.231516  1721 net.cpp:150] Setting up drop6
I1209 11:05:43.231541  1721 net.cpp:157] Top shape: 50 4096 (204800)
I1209 11:05:43.231547  1721 net.cpp:165] Memory required for data: 340550000
I1209 11:05:43.231552  1721 layer_factory.hpp:77] Creating layer fc7
I1209 11:05:43.231567  1721 net.cpp:106] Creating Layer fc7
I1209 11:05:43.231573  1721 net.cpp:454] fc7 <- fc6
I1209 11:05:43.231583  1721 net.cpp:411] fc7 -> fc7
I1209 11:05:43.793658  1721 net.cpp:150] Setting up fc7
I1209 11:05:43.793715  1721 net.cpp:157] Top shape: 50 4096 (204800)
I1209 11:05:43.793721  1721 net.cpp:165] Memory required for data: 341369200
I1209 11:05:43.793737  1721 layer_factory.hpp:77] Creating layer relu7
I1209 11:05:43.793756  1721 net.cpp:106] Creating Layer relu7
I1209 11:05:43.793764  1721 net.cpp:454] relu7 <- fc7
I1209 11:05:43.793776  1721 net.cpp:397] relu7 -> fc7 (in-place)
I1209 11:05:43.794268  1721 net.cpp:150] Setting up relu7
I1209 11:05:43.794291  1721 net.cpp:157] Top shape: 50 4096 (204800)
I1209 11:05:43.794297  1721 net.cpp:165] Memory required for data: 342188400
I1209 11:05:43.794302  1721 layer_factory.hpp:77] Creating layer drop7
I1209 11:05:43.794315  1721 net.cpp:106] Creating Layer drop7
I1209 11:05:43.794320  1721 net.cpp:454] drop7 <- fc7
I1209 11:05:43.794328  1721 net.cpp:397] drop7 -> fc7 (in-place)
I1209 11:05:43.794369  1721 net.cpp:150] Setting up drop7
I1209 11:05:43.794397  1721 net.cpp:157] Top shape: 50 4096 (204800)
I1209 11:05:43.794402  1721 net.cpp:165] Memory required for data: 343007600
I1209 11:05:43.794407  1721 layer_factory.hpp:77] Creating layer fc8
I1209 11:05:43.794420  1721 net.cpp:106] Creating Layer fc8
I1209 11:05:43.794425  1721 net.cpp:454] fc8 <- fc7
I1209 11:05:43.794435  1721 net.cpp:411] fc8 -> fc8
I1209 11:05:43.794852  1721 net.cpp:150] Setting up fc8
I1209 11:05:43.794872  1721 net.cpp:157] Top shape: 50 2 (100)
I1209 11:05:43.794876  1721 net.cpp:165] Memory required for data: 343008000
I1209 11:05:43.794885  1721 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I1209 11:05:43.794895  1721 net.cpp:106] Creating Layer fc8_fc8_0_split
I1209 11:05:43.794900  1721 net.cpp:454] fc8_fc8_0_split <- fc8
I1209 11:05:43.794909  1721 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1209 11:05:43.794919  1721 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1209 11:05:43.794980  1721 net.cpp:150] Setting up fc8_fc8_0_split
I1209 11:05:43.795020  1721 net.cpp:157] Top shape: 50 2 (100)
I1209 11:05:43.795027  1721 net.cpp:157] Top shape: 50 2 (100)
I1209 11:05:43.795032  1721 net.cpp:165] Memory required for data: 343008800
I1209 11:05:43.795037  1721 layer_factory.hpp:77] Creating layer accuracy
I1209 11:05:43.795055  1721 net.cpp:106] Creating Layer accuracy
I1209 11:05:43.795063  1721 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I1209 11:05:43.795069  1721 net.cpp:454] accuracy <- label_data_1_split_0
I1209 11:05:43.795078  1721 net.cpp:411] accuracy -> accuracy
I1209 11:05:43.795094  1721 net.cpp:150] Setting up accuracy
I1209 11:05:43.795106  1721 net.cpp:157] Top shape: (1)
I1209 11:05:43.795111  1721 net.cpp:165] Memory required for data: 343008804
I1209 11:05:43.795116  1721 layer_factory.hpp:77] Creating layer loss
I1209 11:05:43.795135  1721 net.cpp:106] Creating Layer loss
I1209 11:05:43.795145  1721 net.cpp:454] loss <- fc8_fc8_0_split_1
I1209 11:05:43.795151  1721 net.cpp:454] loss <- label_data_1_split_1
I1209 11:05:43.795162  1721 net.cpp:411] loss -> loss
I1209 11:05:43.795176  1721 layer_factory.hpp:77] Creating layer loss
I1209 11:05:43.795436  1721 net.cpp:150] Setting up loss
I1209 11:05:43.795456  1721 net.cpp:157] Top shape: (1)
I1209 11:05:43.795461  1721 net.cpp:160]     with loss weight 1
I1209 11:05:43.795480  1721 net.cpp:165] Memory required for data: 343008808
I1209 11:05:43.795485  1721 net.cpp:226] loss needs backward computation.
I1209 11:05:43.795491  1721 net.cpp:228] accuracy does not need backward computation.
I1209 11:05:43.795496  1721 net.cpp:226] fc8_fc8_0_split needs backward computation.
I1209 11:05:43.795500  1721 net.cpp:226] fc8 needs backward computation.
I1209 11:05:43.795506  1721 net.cpp:226] drop7 needs backward computation.
I1209 11:05:43.795509  1721 net.cpp:226] relu7 needs backward computation.
I1209 11:05:43.795513  1721 net.cpp:226] fc7 needs backward computation.
I1209 11:05:43.795517  1721 net.cpp:226] drop6 needs backward computation.
I1209 11:05:43.795522  1721 net.cpp:226] relu6 needs backward computation.
I1209 11:05:43.795526  1721 net.cpp:226] fc6 needs backward computation.
I1209 11:05:43.795531  1721 net.cpp:226] pool5 needs backward computation.
I1209 11:05:43.795536  1721 net.cpp:226] relu5 needs backward computation.
I1209 11:05:43.795541  1721 net.cpp:226] conv5 needs backward computation.
I1209 11:05:43.795545  1721 net.cpp:226] relu4 needs backward computation.
I1209 11:05:43.795549  1721 net.cpp:226] conv4 needs backward computation.
I1209 11:05:43.795554  1721 net.cpp:226] relu3 needs backward computation.
I1209 11:05:43.795562  1721 net.cpp:226] conv3 needs backward computation.
I1209 11:05:43.795568  1721 net.cpp:226] norm2 needs backward computation.
I1209 11:05:43.795578  1721 net.cpp:226] pool2 needs backward computation.
I1209 11:05:43.795583  1721 net.cpp:226] relu2 needs backward computation.
I1209 11:05:43.795588  1721 net.cpp:226] conv2 needs backward computation.
I1209 11:05:43.795593  1721 net.cpp:226] norm1 needs backward computation.
I1209 11:05:43.795598  1721 net.cpp:226] pool1 needs backward computation.
I1209 11:05:43.795603  1721 net.cpp:226] relu1 needs backward computation.
I1209 11:05:43.795606  1721 net.cpp:226] conv1 needs backward computation.
I1209 11:05:43.795611  1721 net.cpp:228] label_data_1_split does not need backward computation.
I1209 11:05:43.795617  1721 net.cpp:228] data does not need backward computation.
I1209 11:05:43.795621  1721 net.cpp:270] This network produces output accuracy
I1209 11:05:43.795626  1721 net.cpp:270] This network produces output loss
I1209 11:05:43.795646  1721 net.cpp:283] Network initialization done.
I1209 11:05:43.795807  1721 solver.cpp:60] Solver scaffolding done.
I1209 11:05:43.796424  1721 caffe.cpp:213] Starting Optimization
I1209 11:05:43.796443  1721 solver.cpp:280] Solving CaffeNet
I1209 11:05:43.796448  1721 solver.cpp:281] Learning Rate Policy: step
I1209 11:05:43.797727  1721 solver.cpp:338] Iteration 0, Testing net (#0)
I1209 11:08:06.994985  1721 solver.cpp:406]     Test net output #0: accuracy = 0.49888
I1209 11:08:06.995229  1721 solver.cpp:406]     Test net output #1: loss = 0.737795 (* 1 = 0.737795 loss)
I1209 11:08:07.600880  1721 solver.cpp:229] Iteration 0, loss = 0.921441
I1209 11:08:07.600950  1721 solver.cpp:245]     Train net output #0: loss = 0.921441 (* 1 = 0.921441 loss)
I1209 11:08:07.600972  1721 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1209 11:09:37.766943  1721 solver.cpp:229] Iteration 50, loss = 0.80609
I1209 11:09:37.767072  1721 solver.cpp:245]     Train net output #0: loss = 0.80609 (* 1 = 0.80609 loss)
I1209 11:09:37.767086  1721 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1209 11:11:07.877982  1721 solver.cpp:229] Iteration 100, loss = 0.664401
I1209 11:11:07.878124  1721 solver.cpp:245]     Train net output #0: loss = 0.664401 (* 1 = 0.664401 loss)
I1209 11:11:07.878139  1721 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1209 11:12:38.014094  1721 solver.cpp:229] Iteration 150, loss = 0.650545
I1209 11:12:38.014235  1721 solver.cpp:245]     Train net output #0: loss = 0.650545 (* 1 = 0.650545 loss)
I1209 11:12:38.014250  1721 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1209 11:14:08.146913  1721 solver.cpp:229] Iteration 200, loss = 0.627853
I1209 11:14:08.147048  1721 solver.cpp:245]     Train net output #0: loss = 0.627853 (* 1 = 0.627853 loss)
I1209 11:14:08.147063  1721 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1209 11:15:38.276857  1721 solver.cpp:229] Iteration 250, loss = 0.705332
I1209 11:15:38.277017  1721 solver.cpp:245]     Train net output #0: loss = 0.705332 (* 1 = 0.705332 loss)
I1209 11:15:38.277032  1721 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I1209 11:17:08.412267  1721 solver.cpp:229] Iteration 300, loss = 0.625098
I1209 11:17:08.412425  1721 solver.cpp:245]     Train net output #0: loss = 0.625098 (* 1 = 0.625098 loss)
I1209 11:17:08.412439  1721 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I1209 11:18:38.543212  1721 solver.cpp:229] Iteration 350, loss = 0.639654
I1209 11:18:38.543352  1721 solver.cpp:245]     Train net output #0: loss = 0.639654 (* 1 = 0.639654 loss)
I1209 11:18:38.543366  1721 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I1209 11:20:08.691259  1721 solver.cpp:229] Iteration 400, loss = 0.59394
I1209 11:20:08.691398  1721 solver.cpp:245]     Train net output #0: loss = 0.59394 (* 1 = 0.59394 loss)
I1209 11:20:08.691413  1721 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I1209 11:21:38.822103  1721 solver.cpp:229] Iteration 450, loss = 0.608837
I1209 11:21:38.822247  1721 solver.cpp:245]     Train net output #0: loss = 0.608837 (* 1 = 0.608837 loss)
I1209 11:21:38.822262  1721 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I1209 11:23:08.991914  1721 solver.cpp:229] Iteration 500, loss = 0.613491
I1209 11:23:08.992014  1721 solver.cpp:245]     Train net output #0: loss = 0.613491 (* 1 = 0.613491 loss)
I1209 11:23:08.992028  1721 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I1209 11:24:39.111237  1721 solver.cpp:229] Iteration 550, loss = 0.689751
I1209 11:24:39.111374  1721 solver.cpp:245]     Train net output #0: loss = 0.689751 (* 1 = 0.689751 loss)
I1209 11:24:39.111388  1721 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I1209 11:26:09.230190  1721 solver.cpp:229] Iteration 600, loss = 0.501693
I1209 11:26:09.230345  1721 solver.cpp:245]     Train net output #0: loss = 0.501693 (* 1 = 0.501693 loss)
I1209 11:26:09.230358  1721 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I1209 11:27:39.366546  1721 solver.cpp:229] Iteration 650, loss = 0.554686
I1209 11:27:39.366693  1721 solver.cpp:245]     Train net output #0: loss = 0.554686 (* 1 = 0.554686 loss)
I1209 11:27:39.366708  1721 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I1209 11:29:09.517652  1721 solver.cpp:229] Iteration 700, loss = 0.522492
I1209 11:29:09.517791  1721 solver.cpp:245]     Train net output #0: loss = 0.522492 (* 1 = 0.522492 loss)
I1209 11:29:09.517805  1721 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I1209 11:30:39.627328  1721 solver.cpp:229] Iteration 750, loss = 0.537464
I1209 11:30:39.627472  1721 solver.cpp:245]     Train net output #0: loss = 0.537464 (* 1 = 0.537464 loss)
I1209 11:30:39.627487  1721 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I1209 11:32:09.771450  1721 solver.cpp:229] Iteration 800, loss = 0.537202
I1209 11:32:09.771613  1721 solver.cpp:245]     Train net output #0: loss = 0.537202 (* 1 = 0.537202 loss)
I1209 11:32:09.771628  1721 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I1209 11:33:39.913415  1721 solver.cpp:229] Iteration 850, loss = 0.491092
I1209 11:33:39.913563  1721 solver.cpp:245]     Train net output #0: loss = 0.491092 (* 1 = 0.491092 loss)
I1209 11:33:39.913578  1721 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I1209 11:35:10.088776  1721 solver.cpp:229] Iteration 900, loss = 0.534173
I1209 11:35:10.088917  1721 solver.cpp:245]     Train net output #0: loss = 0.534173 (* 1 = 0.534173 loss)
I1209 11:35:10.088932  1721 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I1209 11:36:40.205149  1721 solver.cpp:229] Iteration 950, loss = 0.512131
I1209 11:36:40.205297  1721 solver.cpp:245]     Train net output #0: loss = 0.512131 (* 1 = 0.512131 loss)
I1209 11:36:40.205312  1721 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I1209 11:38:08.518200  1721 solver.cpp:338] Iteration 1000, Testing net (#0)
I1209 11:40:31.834730  1721 solver.cpp:406]     Test net output #0: accuracy = 0.76768
I1209 11:40:31.834905  1721 solver.cpp:406]     Test net output #1: loss = 0.475192 (* 1 = 0.475192 loss)
I1209 11:40:32.419426  1721 solver.cpp:229] Iteration 1000, loss = 0.513405
I1209 11:40:32.419495  1721 solver.cpp:245]     Train net output #0: loss = 0.513405 (* 1 = 0.513405 loss)
I1209 11:40:32.419509  1721 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I1209 11:42:02.565176  1721 solver.cpp:229] Iteration 1050, loss = 0.430741
I1209 11:42:02.565311  1721 solver.cpp:245]     Train net output #0: loss = 0.430741 (* 1 = 0.430741 loss)
I1209 11:42:02.565326  1721 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I1209 11:43:32.719501  1721 solver.cpp:229] Iteration 1100, loss = 0.427413
I1209 11:43:32.719655  1721 solver.cpp:245]     Train net output #0: loss = 0.427413 (* 1 = 0.427413 loss)
I1209 11:43:32.719669  1721 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I1209 11:45:02.863968  1721 solver.cpp:229] Iteration 1150, loss = 0.462775
I1209 11:45:02.864105  1721 solver.cpp:245]     Train net output #0: loss = 0.462775 (* 1 = 0.462775 loss)
I1209 11:45:02.864120  1721 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I1209 11:46:32.988360  1721 solver.cpp:229] Iteration 1200, loss = 0.451257
I1209 11:46:32.988504  1721 solver.cpp:245]     Train net output #0: loss = 0.451257 (* 1 = 0.451257 loss)
I1209 11:46:32.988519  1721 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I1209 11:48:03.147255  1721 solver.cpp:229] Iteration 1250, loss = 0.427445
I1209 11:48:03.147399  1721 solver.cpp:245]     Train net output #0: loss = 0.427445 (* 1 = 0.427445 loss)
I1209 11:48:03.147413  1721 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I1209 11:49:33.287930  1721 solver.cpp:229] Iteration 1300, loss = 0.407169
I1209 11:49:33.288071  1721 solver.cpp:245]     Train net output #0: loss = 0.407169 (* 1 = 0.407169 loss)
I1209 11:49:33.288085  1721 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I1209 11:51:03.479248  1721 solver.cpp:229] Iteration 1350, loss = 0.344335
I1209 11:51:03.479390  1721 solver.cpp:245]     Train net output #0: loss = 0.344335 (* 1 = 0.344335 loss)
I1209 11:51:03.479405  1721 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I1209 11:52:33.659090  1721 solver.cpp:229] Iteration 1400, loss = 0.388572
I1209 11:52:33.659240  1721 solver.cpp:245]     Train net output #0: loss = 0.388572 (* 1 = 0.388572 loss)
I1209 11:52:33.659255  1721 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I1209 11:54:03.804653  1721 solver.cpp:229] Iteration 1450, loss = 0.375657
I1209 11:54:03.804813  1721 solver.cpp:245]     Train net output #0: loss = 0.375657 (* 1 = 0.375657 loss)
I1209 11:54:03.804827  1721 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I1209 11:55:33.934286  1721 solver.cpp:229] Iteration 1500, loss = 0.422873
I1209 11:55:33.934465  1721 solver.cpp:245]     Train net output #0: loss = 0.422873 (* 1 = 0.422873 loss)
I1209 11:55:33.934480  1721 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I1209 11:57:04.072856  1721 solver.cpp:229] Iteration 1550, loss = 0.416721
I1209 11:57:04.073004  1721 solver.cpp:245]     Train net output #0: loss = 0.416721 (* 1 = 0.416721 loss)
I1209 11:57:04.073019  1721 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I1209 11:58:34.206256  1721 solver.cpp:229] Iteration 1600, loss = 0.366969
I1209 11:58:34.206413  1721 solver.cpp:245]     Train net output #0: loss = 0.366969 (* 1 = 0.366969 loss)
I1209 11:58:34.206428  1721 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I1209 12:00:04.360435  1721 solver.cpp:229] Iteration 1650, loss = 0.309056
I1209 12:00:04.360574  1721 solver.cpp:245]     Train net output #0: loss = 0.309056 (* 1 = 0.309056 loss)
I1209 12:00:04.360589  1721 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I1209 12:01:34.501909  1721 solver.cpp:229] Iteration 1700, loss = 0.348552
I1209 12:01:34.502058  1721 solver.cpp:245]     Train net output #0: loss = 0.348552 (* 1 = 0.348552 loss)
I1209 12:01:34.502073  1721 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I1209 12:03:04.643476  1721 solver.cpp:229] Iteration 1750, loss = 0.335785
I1209 12:03:04.643582  1721 solver.cpp:245]     Train net output #0: loss = 0.335785 (* 1 = 0.335785 loss)
I1209 12:03:04.643596  1721 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I1209 12:04:34.782907  1721 solver.cpp:229] Iteration 1800, loss = 0.387203
I1209 12:04:34.783051  1721 solver.cpp:245]     Train net output #0: loss = 0.387203 (* 1 = 0.387203 loss)
I1209 12:04:34.783066  1721 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I1209 12:06:04.916090  1721 solver.cpp:229] Iteration 1850, loss = 0.320587
I1209 12:06:04.916193  1721 solver.cpp:245]     Train net output #0: loss = 0.320587 (* 1 = 0.320587 loss)
I1209 12:06:04.916208  1721 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I1209 12:07:35.055264  1721 solver.cpp:229] Iteration 1900, loss = 0.270537
I1209 12:07:35.055369  1721 solver.cpp:245]     Train net output #0: loss = 0.270537 (* 1 = 0.270537 loss)
I1209 12:07:35.055383  1721 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I1209 12:09:05.186535  1721 solver.cpp:229] Iteration 1950, loss = 0.24374
I1209 12:09:05.186638  1721 solver.cpp:245]     Train net output #0: loss = 0.24374 (* 1 = 0.24374 loss)
I1209 12:09:05.186652  1721 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I1209 12:10:33.531393  1721 solver.cpp:338] Iteration 2000, Testing net (#0)
I1209 12:12:56.818580  1721 solver.cpp:406]     Test net output #0: accuracy = 0.864202
I1209 12:12:56.818722  1721 solver.cpp:406]     Test net output #1: loss = 0.311161 (* 1 = 0.311161 loss)
I1209 12:12:57.402967  1721 solver.cpp:229] Iteration 2000, loss = 0.349287
I1209 12:12:57.403038  1721 solver.cpp:245]     Train net output #0: loss = 0.349287 (* 1 = 0.349287 loss)
I1209 12:12:57.403053  1721 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I1209 12:14:27.544448  1721 solver.cpp:229] Iteration 2050, loss = 0.263688
I1209 12:14:27.544549  1721 solver.cpp:245]     Train net output #0: loss = 0.263688 (* 1 = 0.263688 loss)
I1209 12:14:27.544564  1721 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I1209 12:15:57.667733  1721 solver.cpp:229] Iteration 2100, loss = 0.296868
I1209 12:15:57.667871  1721 solver.cpp:245]     Train net output #0: loss = 0.296868 (* 1 = 0.296868 loss)
I1209 12:15:57.667886  1721 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I1209 12:17:27.809537  1721 solver.cpp:229] Iteration 2150, loss = 0.326645
I1209 12:17:27.809680  1721 solver.cpp:245]     Train net output #0: loss = 0.326645 (* 1 = 0.326645 loss)
I1209 12:17:27.809695  1721 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I1209 12:18:57.997568  1721 solver.cpp:229] Iteration 2200, loss = 0.273595
I1209 12:18:57.997730  1721 solver.cpp:245]     Train net output #0: loss = 0.273595 (* 1 = 0.273595 loss)
I1209 12:18:57.997745  1721 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I1209 12:20:28.129863  1721 solver.cpp:229] Iteration 2250, loss = 0.282663
I1209 12:20:28.130013  1721 solver.cpp:245]     Train net output #0: loss = 0.282663 (* 1 = 0.282663 loss)
I1209 12:20:28.130028  1721 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I1209 12:21:58.276932  1721 solver.cpp:229] Iteration 2300, loss = 0.297998
I1209 12:21:58.277101  1721 solver.cpp:245]     Train net output #0: loss = 0.297998 (* 1 = 0.297998 loss)
I1209 12:21:58.277117  1721 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I1209 12:23:28.423826  1721 solver.cpp:229] Iteration 2350, loss = 0.260115
I1209 12:23:28.423970  1721 solver.cpp:245]     Train net output #0: loss = 0.260115 (* 1 = 0.260115 loss)
I1209 12:23:28.423985  1721 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I1209 12:24:58.549897  1721 solver.cpp:229] Iteration 2400, loss = 0.306827
I1209 12:24:58.550072  1721 solver.cpp:245]     Train net output #0: loss = 0.306827 (* 1 = 0.306827 loss)
I1209 12:24:58.550086  1721 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I1209 12:26:28.728193  1721 solver.cpp:229] Iteration 2450, loss = 0.319072
I1209 12:26:28.728296  1721 solver.cpp:245]     Train net output #0: loss = 0.319072 (* 1 = 0.319072 loss)
I1209 12:26:28.728309  1721 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I1209 12:27:58.878849  1721 solver.cpp:229] Iteration 2500, loss = 0.215829
I1209 12:27:58.879011  1721 solver.cpp:245]     Train net output #0: loss = 0.215829 (* 1 = 0.215829 loss)
I1209 12:27:58.879027  1721 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I1209 12:29:29.027461  1721 solver.cpp:229] Iteration 2550, loss = 0.226079
I1209 12:29:29.027606  1721 solver.cpp:245]     Train net output #0: loss = 0.226079 (* 1 = 0.226079 loss)
I1209 12:29:29.027619  1721 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I1209 12:30:59.198175  1721 solver.cpp:229] Iteration 2600, loss = 0.190752
I1209 12:30:59.198272  1721 solver.cpp:245]     Train net output #0: loss = 0.190752 (* 1 = 0.190752 loss)
I1209 12:30:59.198285  1721 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I1209 12:32:29.338141  1721 solver.cpp:229] Iteration 2650, loss = 0.198145
I1209 12:32:29.338310  1721 solver.cpp:245]     Train net output #0: loss = 0.198145 (* 1 = 0.198145 loss)
I1209 12:32:29.338325  1721 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I1209 12:33:59.450489  1721 solver.cpp:229] Iteration 2700, loss = 0.227478
I1209 12:33:59.450640  1721 solver.cpp:245]     Train net output #0: loss = 0.227478 (* 1 = 0.227478 loss)
I1209 12:33:59.450655  1721 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I1209 12:35:29.573083  1721 solver.cpp:229] Iteration 2750, loss = 0.220776
I1209 12:35:29.573225  1721 solver.cpp:245]     Train net output #0: loss = 0.220776 (* 1 = 0.220776 loss)
I1209 12:35:29.573240  1721 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I1209 12:36:59.720024  1721 solver.cpp:229] Iteration 2800, loss = 0.210332
I1209 12:36:59.720176  1721 solver.cpp:245]     Train net output #0: loss = 0.210332 (* 1 = 0.210332 loss)
I1209 12:36:59.720191  1721 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I1209 12:38:29.848495  1721 solver.cpp:229] Iteration 2850, loss = 0.202746
I1209 12:38:29.848654  1721 solver.cpp:245]     Train net output #0: loss = 0.202746 (* 1 = 0.202746 loss)
I1209 12:38:29.848669  1721 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I1209 12:39:59.990988  1721 solver.cpp:229] Iteration 2900, loss = 0.204068
I1209 12:39:59.991132  1721 solver.cpp:245]     Train net output #0: loss = 0.204068 (* 1 = 0.204068 loss)
I1209 12:39:59.991147  1721 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I1209 12:41:30.118268  1721 solver.cpp:229] Iteration 2950, loss = 0.200076
I1209 12:41:30.118408  1721 solver.cpp:245]     Train net output #0: loss = 0.200076 (* 1 = 0.200076 loss)
I1209 12:41:30.118422  1721 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I1209 12:42:58.435643  1721 solver.cpp:338] Iteration 3000, Testing net (#0)
I1209 12:45:21.982424  1721 solver.cpp:406]     Test net output #0: accuracy = 0.892983
I1209 12:45:21.982585  1721 solver.cpp:406]     Test net output #1: loss = 0.257319 (* 1 = 0.257319 loss)
I1209 12:45:22.565927  1721 solver.cpp:229] Iteration 3000, loss = 0.188809
I1209 12:45:22.566005  1721 solver.cpp:245]     Train net output #0: loss = 0.188809 (* 1 = 0.188809 loss)
I1209 12:45:22.566020  1721 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I1209 12:46:52.671299  1721 solver.cpp:229] Iteration 3050, loss = 0.237562
I1209 12:46:52.671442  1721 solver.cpp:245]     Train net output #0: loss = 0.237562 (* 1 = 0.237562 loss)
I1209 12:46:52.671456  1721 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I1209 12:48:22.797106  1721 solver.cpp:229] Iteration 3100, loss = 0.183147
I1209 12:48:22.797260  1721 solver.cpp:245]     Train net output #0: loss = 0.183147 (* 1 = 0.183147 loss)
I1209 12:48:22.797274  1721 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I1209 12:49:52.930596  1721 solver.cpp:229] Iteration 3150, loss = 0.168064
I1209 12:49:52.930745  1721 solver.cpp:245]     Train net output #0: loss = 0.168064 (* 1 = 0.168064 loss)
I1209 12:49:52.930760  1721 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I1209 12:51:23.085427  1721 solver.cpp:229] Iteration 3200, loss = 0.229279
I1209 12:51:23.085578  1721 solver.cpp:245]     Train net output #0: loss = 0.229279 (* 1 = 0.229279 loss)
I1209 12:51:23.085592  1721 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I1209 12:52:53.219301  1721 solver.cpp:229] Iteration 3250, loss = 0.17385
I1209 12:52:53.219455  1721 solver.cpp:245]     Train net output #0: loss = 0.17385 (* 1 = 0.17385 loss)
I1209 12:52:53.219471  1721 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I1209 12:54:23.393970  1721 solver.cpp:229] Iteration 3300, loss = 0.132927
I1209 12:54:23.394130  1721 solver.cpp:245]     Train net output #0: loss = 0.132927 (* 1 = 0.132927 loss)
I1209 12:54:23.394145  1721 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I1209 12:55:53.556002  1721 solver.cpp:229] Iteration 3350, loss = 0.160488
I1209 12:55:53.556157  1721 solver.cpp:245]     Train net output #0: loss = 0.160488 (* 1 = 0.160488 loss)
I1209 12:55:53.556171  1721 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I1209 12:57:23.685477  1721 solver.cpp:229] Iteration 3400, loss = 0.198284
I1209 12:57:23.685642  1721 solver.cpp:245]     Train net output #0: loss = 0.198284 (* 1 = 0.198284 loss)
I1209 12:57:23.685655  1721 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I1209 12:58:53.798629  1721 solver.cpp:229] Iteration 3450, loss = 0.167167
I1209 12:58:53.798779  1721 solver.cpp:245]     Train net output #0: loss = 0.167167 (* 1 = 0.167167 loss)
I1209 12:58:53.798794  1721 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I1209 13:00:23.955708  1721 solver.cpp:229] Iteration 3500, loss = 0.204846
I1209 13:00:23.955862  1721 solver.cpp:245]     Train net output #0: loss = 0.204846 (* 1 = 0.204846 loss)
I1209 13:00:23.955876  1721 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I1209 13:01:54.089184  1721 solver.cpp:229] Iteration 3550, loss = 0.156316
I1209 13:01:54.089332  1721 solver.cpp:245]     Train net output #0: loss = 0.156316 (* 1 = 0.156316 loss)
I1209 13:01:54.089347  1721 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I1209 13:03:24.236773  1721 solver.cpp:229] Iteration 3600, loss = 0.171158
I1209 13:03:24.236917  1721 solver.cpp:245]     Train net output #0: loss = 0.171158 (* 1 = 0.171158 loss)
I1209 13:03:24.236932  1721 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I1209 13:04:54.380175  1721 solver.cpp:229] Iteration 3650, loss = 0.140098
I1209 13:04:54.380316  1721 solver.cpp:245]     Train net output #0: loss = 0.140098 (* 1 = 0.140098 loss)
I1209 13:04:54.380331  1721 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I1209 13:06:24.520243  1721 solver.cpp:229] Iteration 3700, loss = 0.160671
I1209 13:06:24.520406  1721 solver.cpp:245]     Train net output #0: loss = 0.160671 (* 1 = 0.160671 loss)
I1209 13:06:24.520427  1721 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I1209 13:07:54.640187  1721 solver.cpp:229] Iteration 3750, loss = 0.1528
I1209 13:07:54.640383  1721 solver.cpp:245]     Train net output #0: loss = 0.1528 (* 1 = 0.1528 loss)
I1209 13:07:54.640398  1721 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I1209 13:09:24.780594  1721 solver.cpp:229] Iteration 3800, loss = 0.173602
I1209 13:09:24.780763  1721 solver.cpp:245]     Train net output #0: loss = 0.173602 (* 1 = 0.173602 loss)
I1209 13:09:24.780777  1721 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I1209 13:10:54.928735  1721 solver.cpp:229] Iteration 3850, loss = 0.177492
I1209 13:10:54.928889  1721 solver.cpp:245]     Train net output #0: loss = 0.177492 (* 1 = 0.177492 loss)
I1209 13:10:54.928903  1721 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I1209 13:12:25.057709  1721 solver.cpp:229] Iteration 3900, loss = 0.159309
I1209 13:12:25.057869  1721 solver.cpp:245]     Train net output #0: loss = 0.159309 (* 1 = 0.159309 loss)
I1209 13:12:25.057884  1721 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I1209 13:13:55.225220  1721 solver.cpp:229] Iteration 3950, loss = 0.217419
I1209 13:13:55.225383  1721 solver.cpp:245]     Train net output #0: loss = 0.217419 (* 1 = 0.217419 loss)
I1209 13:13:55.225396  1721 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I1209 13:15:23.553562  1721 solver.cpp:338] Iteration 4000, Testing net (#0)
I1209 13:17:46.874640  1721 solver.cpp:406]     Test net output #0: accuracy = 0.899202
I1209 13:17:46.874799  1721 solver.cpp:406]     Test net output #1: loss = 0.253168 (* 1 = 0.253168 loss)
I1209 13:17:47.459604  1721 solver.cpp:229] Iteration 4000, loss = 0.122354
I1209 13:17:47.459668  1721 solver.cpp:245]     Train net output #0: loss = 0.122354 (* 1 = 0.122354 loss)
I1209 13:17:47.459682  1721 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I1209 13:19:17.604635  1721 solver.cpp:229] Iteration 4050, loss = 0.149398
I1209 13:19:17.604794  1721 solver.cpp:245]     Train net output #0: loss = 0.149398 (* 1 = 0.149398 loss)
I1209 13:19:17.604809  1721 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I1209 13:20:47.724802  1721 solver.cpp:229] Iteration 4100, loss = 0.184903
I1209 13:20:47.724958  1721 solver.cpp:245]     Train net output #0: loss = 0.184903 (* 1 = 0.184903 loss)
I1209 13:20:47.724972  1721 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I1209 13:22:17.847031  1721 solver.cpp:229] Iteration 4150, loss = 0.146574
I1209 13:22:17.847193  1721 solver.cpp:245]     Train net output #0: loss = 0.146574 (* 1 = 0.146574 loss)
I1209 13:22:17.847208  1721 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I1209 13:23:47.987292  1721 solver.cpp:229] Iteration 4200, loss = 0.211163
I1209 13:23:47.987443  1721 solver.cpp:245]     Train net output #0: loss = 0.211163 (* 1 = 0.211163 loss)
I1209 13:23:47.987457  1721 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I1209 13:25:18.142473  1721 solver.cpp:229] Iteration 4250, loss = 0.130646
I1209 13:25:18.142622  1721 solver.cpp:245]     Train net output #0: loss = 0.130646 (* 1 = 0.130646 loss)
I1209 13:25:18.142637  1721 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I1209 13:26:48.288401  1721 solver.cpp:229] Iteration 4300, loss = 0.156436
I1209 13:26:48.288554  1721 solver.cpp:245]     Train net output #0: loss = 0.156436 (* 1 = 0.156436 loss)
I1209 13:26:48.288568  1721 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I1209 13:28:18.438601  1721 solver.cpp:229] Iteration 4350, loss = 0.16386
I1209 13:28:18.438767  1721 solver.cpp:245]     Train net output #0: loss = 0.16386 (* 1 = 0.16386 loss)
I1209 13:28:18.438781  1721 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I1209 13:29:48.597465  1721 solver.cpp:229] Iteration 4400, loss = 0.17104
I1209 13:29:48.597616  1721 solver.cpp:245]     Train net output #0: loss = 0.17104 (* 1 = 0.17104 loss)
I1209 13:29:48.597630  1721 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I1209 13:31:18.736548  1721 solver.cpp:229] Iteration 4450, loss = 0.182914
I1209 13:31:18.736713  1721 solver.cpp:245]     Train net output #0: loss = 0.182914 (* 1 = 0.182914 loss)
I1209 13:31:18.736728  1721 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I1209 13:32:48.872304  1721 solver.cpp:229] Iteration 4500, loss = 0.158551
I1209 13:32:48.872519  1721 solver.cpp:245]     Train net output #0: loss = 0.158551 (* 1 = 0.158551 loss)
I1209 13:32:48.872534  1721 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I1209 13:34:19.020735  1721 solver.cpp:229] Iteration 4550, loss = 0.128642
I1209 13:34:19.020889  1721 solver.cpp:245]     Train net output #0: loss = 0.128642 (* 1 = 0.128642 loss)
I1209 13:34:19.020902  1721 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I1209 13:35:49.151810  1721 solver.cpp:229] Iteration 4600, loss = 0.127023
I1209 13:35:49.151957  1721 solver.cpp:245]     Train net output #0: loss = 0.127023 (* 1 = 0.127023 loss)
I1209 13:35:49.151971  1721 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I1209 13:37:19.274394  1721 solver.cpp:229] Iteration 4650, loss = 0.12683
I1209 13:37:19.274544  1721 solver.cpp:245]     Train net output #0: loss = 0.12683 (* 1 = 0.12683 loss)
I1209 13:37:19.274559  1721 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I1209 13:38:49.408463  1721 solver.cpp:229] Iteration 4700, loss = 0.135505
I1209 13:38:49.408625  1721 solver.cpp:245]     Train net output #0: loss = 0.135505 (* 1 = 0.135505 loss)
I1209 13:38:49.408639  1721 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I1209 13:40:19.570015  1721 solver.cpp:229] Iteration 4750, loss = 0.182589
I1209 13:40:19.570183  1721 solver.cpp:245]     Train net output #0: loss = 0.182589 (* 1 = 0.182589 loss)
I1209 13:40:19.570199  1721 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I1209 13:41:49.695075  1721 solver.cpp:229] Iteration 4800, loss = 0.108798
I1209 13:41:49.695232  1721 solver.cpp:245]     Train net output #0: loss = 0.108798 (* 1 = 0.108798 loss)
I1209 13:41:49.695246  1721 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I1209 13:43:19.844347  1721 solver.cpp:229] Iteration 4850, loss = 0.116522
I1209 13:43:19.844503  1721 solver.cpp:245]     Train net output #0: loss = 0.116522 (* 1 = 0.116522 loss)
I1209 13:43:19.844517  1721 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I1209 13:44:49.987182  1721 solver.cpp:229] Iteration 4900, loss = 0.124544
I1209 13:44:49.987339  1721 solver.cpp:245]     Train net output #0: loss = 0.124544 (* 1 = 0.124544 loss)
I1209 13:44:49.987352  1721 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I1209 13:46:20.151232  1721 solver.cpp:229] Iteration 4950, loss = 0.198665
I1209 13:46:20.151377  1721 solver.cpp:245]     Train net output #0: loss = 0.198665 (* 1 = 0.198665 loss)
I1209 13:46:20.151391  1721 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I1209 13:47:48.475078  1721 solver.cpp:456] Snapshotting to binary proto file /home/ubuntu/cats-dogs/caffe_model/caffe_model_1_iter_5000.caffemodel
I1209 13:47:50.743005  1721 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/ubuntu/cats-dogs/caffe_model/caffe_model_1_iter_5000.solverstate
I1209 13:47:51.127812  1721 solver.cpp:338] Iteration 5000, Testing net (#0)
I1209 13:50:14.345512  1721 solver.cpp:406]     Test net output #0: accuracy = 0.901602
I1209 13:50:14.345671  1721 solver.cpp:406]     Test net output #1: loss = 0.248766 (* 1 = 0.248766 loss)
I1209 13:50:14.931581  1721 solver.cpp:229] Iteration 5000, loss = 0.127288
I1209 13:50:14.931653  1721 solver.cpp:245]     Train net output #0: loss = 0.127288 (* 1 = 0.127288 loss)
I1209 13:50:14.931666  1721 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I1209 13:51:45.046983  1721 solver.cpp:229] Iteration 5050, loss = 0.163398
I1209 13:51:45.047142  1721 solver.cpp:245]     Train net output #0: loss = 0.163398 (* 1 = 0.163398 loss)
I1209 13:51:45.047158  1721 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I1209 13:53:15.210733  1721 solver.cpp:229] Iteration 5100, loss = 0.139505
I1209 13:53:15.210870  1721 solver.cpp:245]     Train net output #0: loss = 0.139505 (* 1 = 0.139505 loss)
I1209 13:53:15.210886  1721 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I1209 13:54:45.391365  1721 solver.cpp:229] Iteration 5150, loss = 0.107808
I1209 13:54:45.391589  1721 solver.cpp:245]     Train net output #0: loss = 0.107808 (* 1 = 0.107808 loss)
I1209 13:54:45.391607  1721 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I1209 13:56:15.513715  1721 solver.cpp:229] Iteration 5200, loss = 0.109277
I1209 13:56:15.513882  1721 solver.cpp:245]     Train net output #0: loss = 0.109277 (* 1 = 0.109277 loss)
I1209 13:56:15.513897  1721 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I1209 13:57:45.671798  1721 solver.cpp:229] Iteration 5250, loss = 0.118527
I1209 13:57:45.671948  1721 solver.cpp:245]     Train net output #0: loss = 0.118527 (* 1 = 0.118527 loss)
I1209 13:57:45.671963  1721 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I1209 13:59:15.807994  1721 solver.cpp:229] Iteration 5300, loss = 0.134119
I1209 13:59:15.808152  1721 solver.cpp:245]     Train net output #0: loss = 0.134119 (* 1 = 0.134119 loss)
I1209 13:59:15.808167  1721 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I1209 14:00:45.965338  1721 solver.cpp:229] Iteration 5350, loss = 0.109533
I1209 14:00:45.965507  1721 solver.cpp:245]     Train net output #0: loss = 0.109533 (* 1 = 0.109533 loss)
I1209 14:00:45.965524  1721 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I1209 14:02:16.125784  1721 solver.cpp:229] Iteration 5400, loss = 0.133864
I1209 14:02:16.125934  1721 solver.cpp:245]     Train net output #0: loss = 0.133864 (* 1 = 0.133864 loss)
I1209 14:02:16.125949  1721 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I1209 14:03:46.244781  1721 solver.cpp:229] Iteration 5450, loss = 0.122434
I1209 14:03:46.244915  1721 solver.cpp:245]     Train net output #0: loss = 0.122434 (* 1 = 0.122434 loss)
I1209 14:03:46.244930  1721 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I1209 14:05:16.391508  1721 solver.cpp:229] Iteration 5500, loss = 0.123284
I1209 14:05:16.391665  1721 solver.cpp:245]     Train net output #0: loss = 0.123284 (* 1 = 0.123284 loss)
I1209 14:05:16.391681  1721 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I1209 14:06:46.514379  1721 solver.cpp:229] Iteration 5550, loss = 0.103745
I1209 14:06:46.514539  1721 solver.cpp:245]     Train net output #0: loss = 0.103745 (* 1 = 0.103745 loss)
I1209 14:06:46.514554  1721 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I1209 14:08:16.659257  1721 solver.cpp:229] Iteration 5600, loss = 0.133872
I1209 14:08:16.659399  1721 solver.cpp:245]     Train net output #0: loss = 0.133872 (* 1 = 0.133872 loss)
I1209 14:08:16.659415  1721 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I1209 14:09:46.801225  1721 solver.cpp:229] Iteration 5650, loss = 0.132734
I1209 14:09:46.801390  1721 solver.cpp:245]     Train net output #0: loss = 0.132734 (* 1 = 0.132734 loss)
I1209 14:09:46.801405  1721 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I1209 14:11:16.964623  1721 solver.cpp:229] Iteration 5700, loss = 0.156112
I1209 14:11:16.964764  1721 solver.cpp:245]     Train net output #0: loss = 0.156112 (* 1 = 0.156112 loss)
I1209 14:11:16.964781  1721 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I1209 14:12:47.099153  1721 solver.cpp:229] Iteration 5750, loss = 0.136721
I1209 14:12:47.099321  1721 solver.cpp:245]     Train net output #0: loss = 0.136721 (* 1 = 0.136721 loss)
I1209 14:12:47.099344  1721 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I1209 14:14:17.247144  1721 solver.cpp:229] Iteration 5800, loss = 0.132206
I1209 14:14:17.247301  1721 solver.cpp:245]     Train net output #0: loss = 0.132206 (* 1 = 0.132206 loss)
I1209 14:14:17.247316  1721 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I1209 14:15:47.377053  1721 solver.cpp:229] Iteration 5850, loss = 0.0901813
I1209 14:15:47.377218  1721 solver.cpp:245]     Train net output #0: loss = 0.0901813 (* 1 = 0.0901813 loss)
I1209 14:15:47.377234  1721 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I1209 14:17:17.520952  1721 solver.cpp:229] Iteration 5900, loss = 0.0719558
I1209 14:17:17.521092  1721 solver.cpp:245]     Train net output #0: loss = 0.0719558 (* 1 = 0.0719558 loss)
I1209 14:17:17.521107  1721 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I1209 14:18:47.657929  1721 solver.cpp:229] Iteration 5950, loss = 0.13496
I1209 14:18:47.658145  1721 solver.cpp:245]     Train net output #0: loss = 0.13496 (* 1 = 0.13496 loss)
I1209 14:18:47.658161  1721 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I1209 14:20:16.035902  1721 solver.cpp:338] Iteration 6000, Testing net (#0)
I1209 14:22:39.557489  1721 solver.cpp:406]     Test net output #0: accuracy = 0.902102
I1209 14:22:39.557656  1721 solver.cpp:406]     Test net output #1: loss = 0.251532 (* 1 = 0.251532 loss)
I1209 14:22:40.140779  1721 solver.cpp:229] Iteration 6000, loss = 0.142632
I1209 14:22:40.140846  1721 solver.cpp:245]     Train net output #0: loss = 0.142632 (* 1 = 0.142632 loss)
I1209 14:22:40.140861  1721 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
